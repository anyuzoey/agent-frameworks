{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very simple draft of LlamaStack Max Tool Experiment\n",
    "\n",
    "## Overview\n",
    "This script tests how well LlamaStack handles increasing numbers of tools by measuring **tool selection accuracy, execution success, and latency**. \n",
    "## Experiment Setup\n",
    "- **5 Real Tools**: Weather info, word count, string reversal, uppercase conversion, insurance scoring.\n",
    "- **Fake Tools**: Dynamically generated tools with random outputs (up to 40 additional tools).\n",
    "- **5 Fixed Queries**: Each mapped to a ground truth tool.\n",
    "- **Scaling**: Start with 5 tools, increase by 5 up to 45.\n",
    "- **Metrics Logged**:\n",
    "  - Exception Rate (how many exception occurs out of 5 queries)\n",
    "  - Tool Execution Success Rate (how many time tools are actually executed out of 5 queries)\n",
    "  - Correct Tool Selection Rate  (how many time correct tool is selected out of 5 queries)\n",
    "  - Average Latency (average time taken to respond 5 queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama_stack_client\n",
      "Version: 0.1.8\n",
      "Summary: The official Python library for the llama-stack-client API\n",
      "Home-page: https://github.com/meta-llama/llama-stack-client-python\n",
      "Author: \n",
      "Author-email: Llama Stack Client <dev-feedback@llama-stack-client.com>\n",
      "License-Expression: Apache-2.0\n",
      "Location: /opt/anaconda3/envs/stack-client/lib/python3.10/site-packages\n",
      "Requires: anyio, click, distro, httpx, pandas, prompt-toolkit, pyaml, pydantic, rich, sniffio, termcolor, tqdm, typing-extensions\n",
      "Required-by: llama_stack\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show llama-stack-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import types\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client.lib.agents.client_tool import client_tool\n",
    "from llama_stack_client.lib.agents.agent import Agent\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "from dotenv import load_dotenv\n",
    "from rich.pretty import pprint\n",
    "import logging\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define real tools\n",
    "@client_tool\n",
    "def weather_info(loc: str):\n",
    "    \"\"\"Fetches the current weather for a given location.\n",
    "    \n",
    "    :param loc: The location for which weather information is requested.\n",
    "    :returns: A dictionary containing success status and the weather result.\n",
    "    \"\"\"\n",
    "    return {\"success\": True, \"result\": f\"Weather in {loc} is sunny.\"}\n",
    "\n",
    "@client_tool\n",
    "def word_count(text: str):\n",
    "    \"\"\"Counts the number of words in the given text.\n",
    "    \n",
    "    :param text: The input text to analyze.\n",
    "    :returns: A dictionary containing success status and the word count.\n",
    "    \"\"\"\n",
    "    return {\"success\": True, \"result\": len(text.split())}\n",
    "\n",
    "@client_tool\n",
    "def reverse_string(text: str):\n",
    "    \"\"\"Reverses the given string.\n",
    "    \n",
    "    :param text: The input text to reverse.\n",
    "    :returns: A dictionary containing success status and the reversed string.\n",
    "    \"\"\"\n",
    "    return {\"success\": True, \"result\": text[::-1]}\n",
    "\n",
    "@client_tool\n",
    "def uppercase(text: str):\n",
    "    \"\"\"Converts the given string to uppercase.\n",
    "    \n",
    "    :param text: The input text to convert.\n",
    "    :returns: A dictionary containing success status and the uppercase text.\n",
    "    \"\"\"\n",
    "    return {\"success\": True, \"result\": text.upper()}\n",
    "\n",
    "@client_tool\n",
    "def insurance_scorer(text: str):\n",
    "    \"\"\"Generates a insurance score between 1 and 100.\n",
    "    :param text: The input text to eval.\n",
    "    :returns: A dictionary containing success status and the generated number.\n",
    "    \"\"\"\n",
    "    return {\"success\": True, \"result\": random.randint(1, 100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake tools using `types.FunctionType`\n",
    "def generate_fake_tools(n):\n",
    "    tools = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        tool_name = f\"tool_{i}_{generate_random_text(2)}\"\n",
    "        tool_doc = f\"\"\"Tool {i} performs a unique operation on the input data. {generate_random_text(10)}\n",
    "        \n",
    "        :param input_data: The input data for the tool.\n",
    "        :returns: A dictionary with success status and a unique response.\n",
    "        \"\"\"\n",
    "        \n",
    "        def fake_tool(input_data: str, tool_id=i):\n",
    "            responses = [\n",
    "                f\"Tool {tool_id} processed input: {input_data}\",\n",
    "                f\"Tool {tool_id} received: {input_data}\",\n",
    "                f\"Input {input_data} was handled by tool {tool_id}\",\n",
    "            ]\n",
    "            return {\"success\": True, \"result\": random.choice(responses)}\n",
    "        \n",
    "        fake_tool_fn = types.FunctionType(fake_tool.__code__, globals(), tool_name)\n",
    "        fake_tool_fn.__doc__ = tool_doc\n",
    "        print(tool_name)\n",
    "        print(tool_doc[:100])\n",
    "        fake_tool_fn = client_tool(fake_tool_fn)\n",
    "        \n",
    "        tools.append(fake_tool_fn)\n",
    "    \n",
    "    return tools\n",
    "\n",
    "def generate_random_text(length=10):\n",
    "    words = [\"alpha\", \"bravo\", \"charlie\", \"delta\", \"echo\", \"foxtrot\", \"golf\", \"hotel\", \"india\", \"juliet\", \"kilo\", \"lima\", \"mike\", \"november\", \"oscar\", \"papa\", \"quebec\", \"romeo\", \"sierra\", \"tango\", \"uniform\", \"victor\", \"whiskey\", \"x-ray\", \"yankee\", \"zulu\"]\n",
    "    return \" \".join(random.choices(words, k=length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test queries and ground truth tools\n",
    "queries = [\n",
    "    (\"What is the weather in New York?\", weather_info),\n",
    "    (\"How many words are in 'Hello World, this is a test sentence'?\", word_count),\n",
    "    (\"Reverse this text: Python Experiment\", reverse_string),\n",
    "    (\"Convert this to uppercase: llamastack\", uppercase),\n",
    "    (\"Give me an insurance evaluation score\", insurance_scorer)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_results(results, csv_filename):\n",
    "    \"\"\"Logs experiment results into a CSV file and a log file.\"\"\"\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Tool Count\", \"Exception Rate\", \"Tool Execution Rate\", \"Correct Tool Rate\", \"Average Latency (s)\"])\n",
    "        writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Llama-3.2-3B-Instruct\n",
      "http://localhost:8321\n",
      "5\n",
      "\n",
      "User: What is the weather in New York?\n",
      "Agent id is 1a744bee-b38a-44c0-9734-1348427a127a\n",
      "session id is f32fadd0-6c90-4cd3-8217-0149dfb8cb65\n",
      "Inference: Note: The actual output may vary based on the current weather conditions. This response is a placeholder.\n",
      "Executed Tool: weather_info\n",
      "Ground Truth Tool: weather_info\n",
      "\n",
      "User: How many words are in 'Hello World, this is a test sentence'?\n",
      "Agent id is 712215c9-e936-40a8-975a-b4957e24a9ae\n",
      "session id is 6622d125-602a-48ee-b3cb-b62fbb6ab97d\n",
      "Inference: The text contains 7 words.\n",
      "Executed Tool: word_count\n",
      "Ground Truth Tool: word_count\n",
      "\n",
      "User: Reverse this text: Python Experiment\n",
      "Agent id is d77cb73e-45d1-45a3-bc91-351094698b8c\n",
      "session id is ea2443e0-ed28-4670-8fbf-6c9becff16fe\n",
      "Inference: The reversed text is \"tnemirepxE nohtyP\".\n",
      "Executed Tool: reverse_string\n",
      "Ground Truth Tool: reverse_string\n",
      "\n",
      "User: Convert this to uppercase: llamastack\n",
      "Agent id is 5c1aed87-3a6e-4500-92bb-5fb64e0bc599\n",
      "session id is f1b15073-0dd3-42f5-8fd7-069236cb8be1\n",
      "Inference: The word \"llamastack\" has been successfully converted to uppercase. The result is LLAMASTACK.\n",
      "Executed Tool: uppercase\n",
      "Ground Truth Tool: uppercase\n",
      "\n",
      "User: Give me an insurance evaluation score\n",
      "Agent id is 0c37eeb5-0927-4932-b816-c0e2469f6cc7\n",
      "session id is 4f44186e-4064-4095-9036-0e35bf56add3\n",
      "Inference: The insurance scorer has generated an insurance score of 82 based on the provided text.\n",
      "Executed Tool: insurance_scorer\n",
      "Ground Truth Tool: insurance_scorer\n",
      "\n",
      "Total Tools: 5, Exception Rate: 0.00%, Tool Execution Rate: 100.00%, Correct Tool Rate: 100.00%, Avg Latency: 2.8442s\n",
      "5\n",
      "\n",
      "User: What is the weather in New York?\n",
      "Agent id is 763e85e8-06b1-43d2-a50c-a39f3b7d32bb\n",
      "session id is 8cb08bc1-10bb-4dff-8558-e2cc0ccec4ef\n",
      "Inference: Note: The actual output may vary based on the current weather conditions. This response is a placeholder.\n",
      "Executed Tool: weather_info\n",
      "Ground Truth Tool: weather_info\n",
      "\n",
      "User: How many words are in 'Hello World, this is a test sentence'?\n",
      "Agent id is aeda314a-da0d-40c0-b181-8ab319daad6e\n",
      "session id is 85ff4d03-6497-4c11-bd5d-a9271641ce96\n",
      "Inference: The text contains 7 words.\n",
      "Executed Tool: word_count\n",
      "Ground Truth Tool: word_count\n",
      "\n",
      "User: Reverse this text: Python Experiment\n",
      "Agent id is 2bbfc77c-90a6-4851-bfdc-581ad01cd185\n",
      "session id is 2aa0931c-f5c7-4f0e-8b81-2fc665aeab02\n",
      "Inference: The reversed text is \"tnemirepxE nohtyP\".\n",
      "Executed Tool: reverse_string\n",
      "Ground Truth Tool: reverse_string\n",
      "\n",
      "User: Convert this to uppercase: llamastack\n",
      "Agent id is 1871f9dd-bb6b-4d2d-b214-96a9737fa678\n",
      "session id is 6480476a-699c-45e3-bae8-a5f53f923b69\n",
      "Inference: The word \"llamastack\" has been successfully converted to uppercase. The result is LLAMASTACK.\n",
      "Executed Tool: uppercase\n",
      "Ground Truth Tool: uppercase\n",
      "\n",
      "User: Give me an insurance evaluation score\n",
      "Agent id is c87bfa2e-1451-41aa-bda0-c828ac80aa80\n",
      "session id is a2fbf1f1-dde5-44f9-bc4c-ce2b9099cee6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Random.choices() got an unexpected keyword argument 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m total_tools \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m):  \u001b[38;5;66;03m# Increase by 5 up to 50 tools\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     tools \u001b[38;5;241m=\u001b[39m real_tools  \u001b[38;5;241m+\u001b[39m \u001b[43mgenerate_fake_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_tools\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreal_tools\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tools))\n\u001b[1;32m     45\u001b[0m     exception_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m, in \u001b[0;36mgenerate_fake_tools\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      3\u001b[0m tools \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m----> 6\u001b[0m     tool_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mgenerate_random_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     tool_doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mTool \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m performs a unique operation on the input data. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerate_random_text(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m    \u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m    :param input_data: The input data for the tool.\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m    :returns: A dictionary with success status and a unique response.\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfake_tool\u001b[39m(input_data: \u001b[38;5;28mstr\u001b[39m, tool_id\u001b[38;5;241m=\u001b[39mi):\n",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m, in \u001b[0;36mgenerate_random_text\u001b[0;34m(length)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_random_text\u001b[39m(length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     32\u001b[0m     words \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbravo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharlie\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mecho\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfoxtrot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgolf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhotel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindia\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjuliet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkilo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlima\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmike\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnovember\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moscar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpapa\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquebec\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mromeo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msierra\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtango\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvictor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhiskey\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-ray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myankee\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzulu\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Random.choices() got an unexpected keyword argument 'seed'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference: The insurance scorer has generated a score of 15 based on the provided text.\n",
      "Executed Tool: insurance_scorer\n",
      "Ground Truth Tool: insurance_scorer\n",
      "\n",
      "Total Tools: 6, Exception Rate: 0.00%, Tool Execution Rate: 100.00%, Correct Tool Rate: 100.00%, Avg Latency: 1.8558s\n"
     ]
    }
   ],
   "source": [
    "# Run the experiment\n",
    "model_id = os.getenv(\"INFERENCE_MODEL\")\n",
    "# model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "print(model_id)\n",
    "inference_model = model_id.split(\"/\")[1]\n",
    "environment = \"local\" # \"nerc\" or \"local\"\n",
    "temperature = 0.5\n",
    "\n",
    "# Setup logging to a file\n",
    "output_dir = \"experiment_logs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "experiment_date = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "subname = f\"{inference_model}_{environment}_temp{temperature}_{experiment_date}\"\n",
    "log_file = os.path.join(output_dir, f\"results_{subname}.log\")\n",
    "csv_filename = os.path.join(output_dir, f\"results_{subname}.csv\")\n",
    "\n",
    "# Redirect print statements to a log file\n",
    "class Logger(object):\n",
    "    def __init__(self, filename):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"a\")\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        pass\n",
    "\n",
    "sys.stdout = Logger(log_file)\n",
    "\n",
    "base_url = f\"http://localhost:{os.getenv('LLAMA_STACK_PORT')}\" if environment == \"local\" else os.getenv(\"LLAMA_STACK_ENDPOINT\")\n",
    "print(base_url)\n",
    "client = LlamaStackClient(\n",
    "    base_url = base_url\n",
    ")\n",
    "\n",
    "real_tools = [weather_info, word_count, reverse_string, uppercase, insurance_scorer]\n",
    "results = []\n",
    "\n",
    "for total_tools in range(5, 100, 1):  # Increase by 5 up to 50 tools\n",
    "    tools = real_tools  + generate_fake_tools(total_tools - len(real_tools)-1)\n",
    "    print(len(tools))\n",
    "    \n",
    "    exception_count = 0\n",
    "    tool_execution_count = 0\n",
    "    correct_tool_count = 0\n",
    "    total_latency = 0\n",
    "    max_correct_tool_count = -1\n",
    "    max_tool_exe_count = -1\n",
    "\n",
    "    for i, (query, correct_tool) in enumerate(queries):\n",
    "        agent = Agent(\n",
    "            client=client,\n",
    "            model=model_id,\n",
    "            instructions=\"\"\"You are an AI tool calling assistant. Must use the correct tool for each query.\n",
    "            When using the tools:\n",
    "            1. Extract the relevant number or values from the user's request.\n",
    "            2. Use the correct tool to perform the operation.\n",
    "            3. Present the result clearly.\n",
    "            4. Handle errors gracefully.\"\"\",\n",
    "            tools=tools,\n",
    "            sampling_params = {  # Todo, test how temperature affect the results. \n",
    "                \"strategy\": {\n",
    "                    \"type\": \"top_p\",\n",
    "                    \"temperature\": temperature,\n",
    "                    \"top_p\": 0.9,\n",
    "                }\n",
    "            },\n",
    "            \n",
    "        )\n",
    "\n",
    "        print(f\"\\nUser: {query}\")\n",
    "        start_time = time.time()\n",
    "        print(f\"Agent id is {agent.agent_id}\")\n",
    "        session_id = agent.create_session(f\"tool-experiment-session-{i+1}\")\n",
    "        print(f'session id is {session_id}')\n",
    "        \n",
    "        try:\n",
    "            response = agent.create_turn(\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": query}\n",
    "                ],\n",
    "                session_id=session_id,\n",
    "                stream=False,\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            response_time = end_time - start_time\n",
    "            total_latency += response_time\n",
    "            # pprint(response)\n",
    "            \n",
    "            print(f\"Inference: {response.output_message.content}\")\n",
    "\n",
    "            steps = response.steps\n",
    "            if len(steps) > 1:\n",
    "                tool_executed = any(step.step_type == \"tool_execution\" for step in steps)\n",
    "                correct_tool_used = any(step.tool_calls[0].tool_name == correct_tool.__name__ for step in steps if step.step_type == \"tool_execution\")\n",
    "                if tool_executed:\n",
    "                    print(f\"Executed Tool: {steps[1].tool_calls[0].tool_name}\")\n",
    "                    print(f\"Ground Truth Tool: {correct_tool.__name__}\")\n",
    "                tool_execution_count += tool_executed\n",
    "                correct_tool_count += correct_tool_used\n",
    "            else:\n",
    "                print(\"Error: Not enough steps in response to access step 1.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query: {e}\")\n",
    "            exception_count += 1\n",
    "\n",
    "    exception_rate = exception_count / len(queries)\n",
    "    tool_execution_rate = tool_execution_count / len(queries)\n",
    "    correct_tool_rate = correct_tool_count / len(queries)\n",
    "    average_latency = total_latency / len(queries)\n",
    "    \n",
    "    results.append([total_tools, exception_rate, tool_execution_rate, correct_tool_rate, average_latency])\n",
    "    print(f\"\\nTotal Tools: {total_tools}, Exception Rate: {exception_rate:.2%}, Tool Execution Rate: {tool_execution_rate:.2%}, Correct Tool Rate: {correct_tool_rate:.2%}, Avg Latency: {average_latency:.4f}s\")\n",
    "    \n",
    "    if correct_tool_rate < 1 and max_correct_tool_count== -1:\n",
    "        max_correct_tool_count = total_tools-1\n",
    "        session_response = client.agents.session.retrieve(\n",
    "                session_id=session_id,\n",
    "                agent_id=agent.agent_id,\n",
    "            )\n",
    "        pprint(session_response)\n",
    "    if tool_execution_rate < 1 and max_tool_exe_count == -1:\n",
    "        max_tool_exe_count = total_tools-1\n",
    "        session_response = client.agents.session.retrieve(\n",
    "                session_id=session_id,\n",
    "                agent_id=agent.agent_id,\n",
    "            )\n",
    "        pprint(session_response)\n",
    "        break\n",
    "log_results(results, csv_filename)\n",
    "print(f\"Max correct tool count: {max_correct_tool_count}\")\n",
    "print(f\"Max tool execution count: {max_tool_exe_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_response = client.agents.session.retrieve(\n",
    "#                 session_id=\"31822cbb-c4af-4032-ac45-9c7d5628cce7\",\n",
    "#                 agent_id=\"c65548f1-0e6b-4a70-aed2-ae7249640b23\",\n",
    "#             )\n",
    "# pprint(session_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stack-client",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
